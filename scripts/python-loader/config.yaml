log_level: INFO  # Set logging level

connection_params:
  dialect: cockroachdb
  user: your_username
  password: ${DB_PASSWORD}
  host: your_host
  port: 26257
  dbname: your_dbname
  sslmode: verify-full
  sslrootcert: /path/to/your/ssl/rootcert

tables:
  - table_name: "emp"
    file_path: "<path_to_csv_file>"
    file_format: "csv"
    batch_size: 1000
    num_threads: 4  # Specify the number of threads here
    truncate_table: true # Whether to truncate the table before loading data
    generate_fake_data: false
    num_fake_records: 100000
    columns:
      empno:
        faker_method: unique_int
        data_type: int
      fname:
        faker_method: first_name  # Generate random first name
        data_type: str
      lname:
        faker_method: last_name  # Generate random last name
        data_type: str
      job:
        faker_method: job
        data_type: str
      mgr:
        faker_method: random_int
        data_type: int
      hiredate:
        faker_method: date_time
        data_type: datetime
      sal:
        faker_method: pydecimal(left_digits=5, right_digits=2, positive=True)
        data_type: float
      comm:
        faker_method: pydecimal(left_digits=5, right_digits=2, positive=True)
        data_type: float
      dept:
        faker_method: random_int
        data_type: int
  - table_name: customers  # Existing Customers table configuration
    batch_size: 1000
    generate_fake_data: true
    num_fake_records: 10000
    columns:
      customer_id:
        faker_method: uuid4
        data_type: uuid
      first_name:
        faker_method: first_name
        data_type: str
      last_name:
        faker_method: last_name
        data_type: str
      email:
        faker_method: unique.email
        data_type: str
      phone_number:
        faker_method: numerify(text='###-###-####')
        data_type: str
      address:
        faker_method: address
        data_type: str
      date_of_birth:
        faker_method: date_of_birth
        data_type: date
      created_at:
        faker_method: date_time_this_decade
        data_type: datetime

  - table_name: accounts  # Accounts table configuration
    batch_size: 1000
    generate_fake_data: true
    num_fake_records: 5000  # Generate 5000 fake records for the Accounts table
    columns:
      account_id:
        faker_method: uuid4
        data_type: uuid
      customer_id:
        faker_method: uuid4  # For simplicity; in practice, these should match existing customer IDs
        data_type: uuid
      account_type:
        faker_method: random_element(elements=['Checking', 'Savings', 'Credit'])
        data_type: str
      balance:
        faker_method: pydecimal(left_digits=10, right_digits=2, positive=True)
        data_type: float
      created_at:
        faker_method: date_time_this_decade
        data_type: datetime

  - table_name: transactions  # Transactions table configuration
    batch_size: 1000
    generate_fake_data: true
    num_fake_records: 20000  # Generate 20000 fake records for the Transactions table
    columns:
      transaction_id:
        faker_method: uuid4
        data_type: uuid
      account_id:
        faker_method: uuid4  # For simplicity; in practice, these should match existing account IDs
        data_type: uuid
      amount:
        faker_method: pydecimal(left_digits=10, right_digits=2, positive=True)
        data_type: float
      transaction_type:
        faker_method: random_element(elements=['Deposit', 'Withdrawal', 'Transfer', 'Payment'])
        data_type: str
      transaction_date:
        faker_method: date_time_this_year
        data_type: datetime
      description:
        faker_method: sentence(nb_words=6)
        data_type: str

# Alerting configuration
slack_token: ${SLACK_TOKEN}
slack_channel: your_slack_channel

alert_email: your_email@example.com
smtp_server: smtp.example.com

# Schedule configuration
schedule_time: 60  # Run the loader every 60 minutes
